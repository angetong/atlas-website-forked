- id: MLCS0000
  object-type: case-study
  name: Microsoft Edge AI - Evasion
  summary: 'The Azure Red Team performed a red team exercise on a new Microsoft product
    designed for running AI workloads at the Edge.

    '
  incident-date: '2020-02-01'
  procedure:
  - tactic: org.mitre.attack.enterprise.TA0043
    technique: MLT0000
    description: 'The team first performed reconnaissance to gather information about
      the target ML model.

      '
  - tactic: org.mitre.attack.enterprise.TA0043
    technique: MLT0001
    description: 'The team identified and obtained the publically available base model.

      '
  - tactic: org.mitre.attack.enterprise.TA0043
    technique: MLT0004
    description: 'The team obtained the datasets used by the model.

      '
  - tactic: MLTA0000
    technique: MLT0017
    description: 'Then, used a publicly available version of the ML model, started
      sending queries and analyzing the responses (inferences) from the ML model.

      Using this, the red team created an automated system that continuously manipulated
      an original target image, that tricked the ML model into producing incorrect
      inferences, but the perturbations in the image were unnoticeable to the human
      eye.

      '
  - tactic: MLTA0000
    technique: MLT0016
    description: 'Feeding this perturbed image, the red team was able to evade the
      ML model into misclassifying the input image.

      '
  reported-by: Microsoft
  verified-by: Microsoft
  sources:
  - Microsoft
