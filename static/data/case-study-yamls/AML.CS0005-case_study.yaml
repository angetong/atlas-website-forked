meta:
  email: ''
study:
  name: >-
    Attack on Machine Translation Service - Google Translate, Bing Translator,
    and Systran Translate
  summary: >
    Machine translation services (such as Google Translate, Bing Translator, and
    Systran Translate) provide public-facing UIs and APIs.

    A research group at UC Berkeley utilized these public endpoints to create a
    replicated model with near-production, state-of-the-art translation quality.

    Beyond demonstrating that IP can be stolen from a black-box system, they
    used the replicated model to successfully transfer adversarial examples to
    the real production services.

    These adversarial inputs successfully cause targeted word flips, vulgar
    outputs, and dropped sentences on Google Translate and Systran Translate
    websites.
  incident-date: 2020-04-30T00:00:00.000Z
  incident-date-granularity: DATE
  procedure:
    - tactic: TA0043
      technique: AML.T0000
      description: >+
        The researchers used published research papers to identify the datasets
        and model architectures used by the target translation services.

    - tactic: TA0042
      technique: AML.T0002.000
      description: >+
        The researchers gathered similar datasets that the target translation
        services used.

    - tactic: TA0042
      technique: AML.T0002.001
      description: >+
        The researchers gathered similar model architectures that the target
        translation services used.

    - tactic: AML.TA0000
      technique: AML.T0040
      description: >+
        They abuse a public facing application to query the model and produce
        machine translated sentence pairs as training data.

    - tactic: AML.TA0001
      technique: AML.T0006
      description: >+
        Using these translated sentence pairs, the researchers trained a model
        that replicates the behavior of the target model.

    - tactic: TA0040
      technique: AML.T0045
      description: >+
        By replicating the model with high fidelity, the researchers
        demonstrated that an adversary could steal a model and violate the
        victim's intellectual property rights.

    - tactic: AML.TA0001
      technique: AML.T0043.002
      description: >+
        The replicated models were used to generate adversarial examples that
        successfully transferred to the black-box translation services.

    - tactic: TA0040
      technique: AML.T0015
      description: >+
        The adversarial examples were used to evade the machine translation
        services.

  reported-by: >-
    Work by Eric Wallace, Mitchell Stern, Dawn Song and reported by Kenny Song
    (@helloksong)
  references:
    - sourceDescription: ''
      url: https://arxiv.org/abs/2004.15015
    - sourceDescription: ''
      url: https://www.ericswallace.com/imitation
