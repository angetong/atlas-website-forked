meta:
  email: ''
study:
  name: Microsoft - Azure Service
  summary: >
    The Azure Red Team and Azure Trustworthy ML team performed a red team
    exercise on an internal Azure service with the intention of disrupting its
    service. This operation had a combination of traditional ATT&CK enterprise
    techniques such as finding Valid account, and Executing code via an API --
    all interleaved with adversarial ML specific steps such as offline and
    online evasion examples.
  incident-date: 2020-01-01T00:00:00.000Z
  incident-date-granularity: DATE
  procedure:
    - tactic: TA0043
      technique: AML.T0000
      description: >+
        The team first performed reconnaissance to gather information about the
        target ML model.

    - tactic: TA0001
      technique: T1078
      description: |+
        The team used a valid account to gain access to the network.

    - tactic: TA0009
      technique: AML.T0035
      description: >+
        The team found the model file of the target ML model and the necessary
        training data.

    - tactic: AML.TA0001
      technique: AML.T0043.000
      description: >+
        Using the target model and data, the red team crafted evasive
        adversarial data.

    - tactic: AML.TA0000
      technique: AML.T0040
      description: |+
        The team used an exposed API to access the target model.

    - tactic: TA0040
      technique: AML.T0015
      description: >+
        The team performed an online evasion attack by replaying the adversarial
        examples, which helped achieve this goal.

  reported-by: Microsoft (Azure Trustworthy Machine Learning)
  references: []
