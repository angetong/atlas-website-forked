meta:
  email: ''
study:
  name: Microsoft Edge AI - Evasion
  summary: >
    The Azure Red Team performed a red team exercise on a new Microsoft product
    designed for running AI workloads at the Edge.
  incident-date: 2020-02-01T00:00:00.000Z
  incident-date-granularity: DATE
  procedure:
    - tactic: TA0043
      technique: AML.T0000
      description: >+
        The team first performed reconnaissance to gather information about the
        target ML model.

    - tactic: TA0042
      technique: AML.T0002
      description: |+
        The team identified and obtained the publicly available base model.

    - tactic: AML.TA0000
      technique: AML.T0040
      description: >+
        Then using the publicly available version of the ML model, started
        sending queries and analyzing the responses (inferences) from the ML
        model.

    - tactic: AML.TA0001
      technique: AML.T0043.001
      description: >+
        The red team created an automated system that continuously manipulated
        an original target image, that tricked the ML model into producing
        incorrect inferences, but the perturbations in the image were
        unnoticeable to the human eye.

    - tactic: TA0040
      technique: AML.T0015
      description: >+
        Feeding this perturbed image, the red team was able to evade the ML
        model by causing misclassifications.

  reported-by: Microsoft
  references: []
