{"versions": {"layer": "4.2", "navigator": "4.2"}, "domain": "atlas-v2-+-enterprise-v9-atlas", "name": "ATLAS Case Study Frequency", "description": "Heatmap of techniques used in ATLAS case studies", "techniques": [{"techniqueID": "AML.T0000.001", "score": 1, "tactic": "reconnaissance"}, {"techniqueID": "AML.T0002.000", "score": 6, "tactic": "resource-development"}, {"techniqueID": "AML.T0005", "score": 4, "showSubtechniques": true, "tactic": "ml-attack-staging"}, {"techniqueID": "AML.T0043.003", "score": 2, "tactic": "ml-attack-staging"}, {"techniqueID": "AML.T0042", "score": 2, "showSubtechniques": true, "tactic": "ml-attack-staging"}, {"techniqueID": "AML.T0015", "score": 4, "showSubtechniques": true, "tactic": "defense-evasion"}, {"techniqueID": "AML.T0000", "score": 6, "showSubtechniques": true, "tactic": "reconnaissance"}, {"techniqueID": "AML.T0002", "score": 3, "showSubtechniques": true, "tactic": "resource-development"}, {"techniqueID": "AML.T0017", "score": 3, "showSubtechniques": true, "tactic": "resource-development"}, {"techniqueID": "AML.T0043.001", "score": 2, "tactic": "ml-attack-staging"}, {"techniqueID": "AML.T0042", "score": 2, "showSubtechniques": true, "tactic": "ml-attack-staging"}, {"techniqueID": "AML.T0015", "score": 4, "showSubtechniques": true, "tactic": "defense-evasion"}, {"techniqueID": "AML.T0016", "score": 3, "showSubtechniques": true, "tactic": "resource-development"}, {"techniqueID": "AML.T0043", "score": 1, "showSubtechniques": true, "tactic": "ml-attack-staging"}, {"techniqueID": "AML.T0010.002", "score": 2, "tactic": "initial-access"}, {"techniqueID": "AML.T0020", "score": 2, "showSubtechniques": true, "tactic": "persistence"}, {"techniqueID": "T1594", "score": 2, "tactic": "reconnaissance"}, {"techniqueID": "AML.T0047", "score": 2, "showSubtechniques": true, "tactic": "ml-model-access"}, {"techniqueID": "AML.T0017", "score": 3, "showSubtechniques": true, "tactic": "resource-development"}, {"techniqueID": "AML.T0043.003", "score": 2, "tactic": "ml-attack-staging"}, {"techniqueID": "AML.T0015", "score": 4, "showSubtechniques": true, "tactic": "defense-evasion"}, {"techniqueID": "T1583", "score": 1, "tactic": "resource-development"}, {"techniqueID": "T1588.002", "score": 1, "showSubtechniques": true, "tactic": "resource-development"}, {"techniqueID": "AML.T0016", "score": 3, "showSubtechniques": true, "tactic": "resource-development"}, {"techniqueID": "T1213", "score": 1, "tactic": "collection"}, {"techniqueID": "T1585", "score": 1, "tactic": "resource-development"}, {"techniqueID": "AML.T0047", "score": 2, "showSubtechniques": true, "tactic": "ml-model-access"}, {"techniqueID": "AML.T0015", "score": 6, "showSubtechniques": true, "tactic": "impact"}, {"techniqueID": "AML.T0000", "score": 6, "showSubtechniques": true, "tactic": "reconnaissance"}, {"techniqueID": "AML.T0002.000", "score": 6, "tactic": "resource-development"}, {"techniqueID": "AML.T0002.001", "score": 2, "tactic": "resource-development"}, {"techniqueID": "AML.T0040", "score": 5, "showSubtechniques": true, "tactic": "ml-model-access"}, {"techniqueID": "AML.T0006", "score": 1, "showSubtechniques": true, "tactic": "ml-attack-staging"}, {"techniqueID": "AML.T0045", "score": 1, "showSubtechniques": true, "tactic": "impact"}, {"techniqueID": "AML.T0043.002", "score": 2, "tactic": "ml-attack-staging"}, {"techniqueID": "AML.T0015", "score": 6, "showSubtechniques": true, "tactic": "impact"}, {"techniqueID": "T1078", "score": 3, "tactic": "initial-access"}, {"techniqueID": "AML.T0000", "score": 6, "showSubtechniques": true, "tactic": "reconnaissance"}, {"techniqueID": "AML.T0002.001", "score": 2, "tactic": "resource-development"}, {"techniqueID": "AML.T0002.000", "score": 6, "tactic": "resource-development"}, {"techniqueID": "AML.T0008", "score": 1, "showSubtechniques": true, "tactic": "resource-development"}, {"techniqueID": "AML.T0005", "score": 4, "showSubtechniques": true, "tactic": "ml-attack-staging"}, {"techniqueID": "AML.T0002", "score": 3, "showSubtechniques": true, "tactic": "resource-development"}, {"techniqueID": "AML.T0002.000", "score": 6, "tactic": "resource-development"}, {"techniqueID": "AML.T0005", "score": 4, "showSubtechniques": true, "tactic": "ml-attack-staging"}, {"techniqueID": "AML.T0043.000", "score": 3, "tactic": "ml-attack-staging"}, {"techniqueID": "AML.T0043.002", "score": 2, "tactic": "ml-attack-staging"}, {"techniqueID": "AML.T0040", "score": 5, "showSubtechniques": true, "tactic": "ml-model-access"}, {"techniqueID": "AML.T0010.002", "score": 2, "tactic": "initial-access"}, {"techniqueID": "AML.T0020", "score": 2, "showSubtechniques": true, "tactic": "persistence"}, {"techniqueID": "AML.T0031", "score": 1, "showSubtechniques": true, "tactic": "impact"}, {"techniqueID": "AML.T0000", "score": 6, "showSubtechniques": true, "tactic": "reconnaissance"}, {"techniqueID": "T1078", "score": 3, "tactic": "initial-access"}, {"techniqueID": "AML.T0035", "score": 1, "showSubtechniques": true, "tactic": "collection"}, {"techniqueID": "AML.T0043.000", "score": 3, "tactic": "ml-attack-staging"}, {"techniqueID": "AML.T0040", "score": 5, "showSubtechniques": true, "tactic": "ml-model-access"}, {"techniqueID": "AML.T0015", "score": 6, "showSubtechniques": true, "tactic": "impact"}, {"techniqueID": "AML.T0000", "score": 6, "showSubtechniques": true, "tactic": "reconnaissance"}, {"techniqueID": "AML.T0002", "score": 3, "showSubtechniques": true, "tactic": "resource-development"}, {"techniqueID": "AML.T0040", "score": 5, "showSubtechniques": true, "tactic": "ml-model-access"}, {"techniqueID": "AML.T0043.001", "score": 2, "tactic": "ml-attack-staging"}, {"techniqueID": "AML.T0015", "score": 6, "showSubtechniques": true, "tactic": "impact"}, {"techniqueID": "AML.T0000", "score": 6, "showSubtechniques": true, "tactic": "reconnaissance"}, {"techniqueID": "T1078", "score": 3, "tactic": "initial-access"}, {"techniqueID": "AML.T0040", "score": 5, "showSubtechniques": true, "tactic": "ml-model-access"}, {"techniqueID": "AML.T0013", "score": 1, "showSubtechniques": true, "tactic": "discovery"}, {"techniqueID": "AML.T0002.000", "score": 6, "tactic": "resource-development"}, {"techniqueID": "AML.T0005", "score": 4, "showSubtechniques": true, "tactic": "ml-attack-staging"}, {"techniqueID": "AML.T0043.000", "score": 3, "tactic": "ml-attack-staging"}, {"techniqueID": "AML.T0041", "score": 1, "showSubtechniques": true, "tactic": "ml-model-access"}, {"techniqueID": "AML.T0015", "score": 6, "showSubtechniques": true, "tactic": "impact"}, {"techniqueID": "T1593.002", "score": 1, "showSubtechniques": true, "tactic": "reconnaissance"}, {"techniqueID": "AML.T0044", "score": 1, "showSubtechniques": true, "tactic": {"id": "AML.TA0000", "name": "ML Model Access", "object-type": "tactic", "description": "An adversary is attempting to gain some level of access to a machine learning model.\n\nML Model Access consists of techniques that use various types of access to the machine learning model that can be used by the adversary to gain information, develop attacks, and as a means to input data to the model.\nThe level of access can range from the full knowledge of the internals of the model to access to the physical environment where data is collected for use in the machine learning model.\nThe adversary may use varying levels of model access during the course of their attack, from staging the attack to impacting the target system..\n"}}, {"techniqueID": "AML.T0016", "score": 3, "showSubtechniques": true, "tactic": "resource-development"}, {"techniqueID": "AML.T0018", "score": 1, "showSubtechniques": true, "tactic": "persistence"}, {"techniqueID": "AML.T0042", "score": 2, "showSubtechniques": true, "tactic": {"id": "AML.TA0001", "name": "ML Attack Staging", "object-type": "tactic", "description": "An adversary is leveraging their knowledge of and access to the target system to tailor the attack.\n\nML Attack Staging consists of techniques adversaries use to prepare their attack on the target ML model.\nTechniques can include training proxy models, poisoning the target model, and crafting adversarial data to feed the target model.\nSome of these techniques can be performed in an offline manor and are thus difficult to mitigate.\nThese techniques are often used to achieve the adversary's end goal.\n"}}, {"techniqueID": "AML.T0010.003", "score": 1, "tactic": "initial-access"}, {"techniqueID": "AML.T0043.004", "score": 1, "tactic": {"id": "AML.TA0001", "name": "ML Attack Staging", "object-type": "tactic", "description": "An adversary is leveraging their knowledge of and access to the target system to tailor the attack.\n\nML Attack Staging consists of techniques adversaries use to prepare their attack on the target ML model.\nTechniques can include training proxy models, poisoning the target model, and crafting adversarial data to feed the target model.\nSome of these techniques can be performed in an offline manor and are thus difficult to mitigate.\nThese techniques are often used to achieve the adversary's end goal.\n"}}, {"techniqueID": "AML.T0041", "score": 1, "showSubtechniques": true, "tactic": {"id": "AML.TA0000", "name": "ML Model Access", "object-type": "tactic", "description": "An adversary is attempting to gain some level of access to a machine learning model.\n\nML Model Access consists of techniques that use various types of access to the machine learning model that can be used by the adversary to gain information, develop attacks, and as a means to input data to the model.\nThe level of access can range from the full knowledge of the internals of the model to access to the physical environment where data is collected for use in the machine learning model.\nThe adversary may use varying levels of model access during the course of their attack, from staging the attack to impacting the target system..\n"}}, {"techniqueID": "AML.T0015", "score": 6, "showSubtechniques": true, "tactic": "impact"}, {"techniqueID": "AML.T0001", "score": 1, "showSubtechniques": true, "tactic": "reconnaissance"}, {"techniqueID": "T1594", "score": 2, "tactic": "reconnaissance"}, {"techniqueID": "AML.T0047", "score": 1, "showSubtechniques": true, "tactic": {"id": "AML.TA0000", "name": "ML Model Access", "object-type": "tactic", "description": "An adversary is attempting to gain some level of access to a machine learning model.\n\nML Model Access consists of techniques that use various types of access to the machine learning model that can be used by the adversary to gain information, develop attacks, and as a means to input data to the model.\nThe level of access can range from the full knowledge of the internals of the model to access to the physical environment where data is collected for use in the machine learning model.\nThe adversary may use varying levels of model access during the course of their attack, from staging the attack to impacting the target system..\n"}}, {"techniqueID": "AML.T0002.000", "score": 6, "tactic": "resource-development"}, {"techniqueID": "AML.T0005", "score": 1, "showSubtechniques": true, "tactic": {"id": "AML.TA0001", "name": "ML Attack Staging", "object-type": "tactic", "description": "An adversary is leveraging their knowledge of and access to the target system to tailor the attack.\n\nML Attack Staging consists of techniques adversaries use to prepare their attack on the target ML model.\nTechniques can include training proxy models, poisoning the target model, and crafting adversarial data to feed the target model.\nSome of these techniques can be performed in an offline manor and are thus difficult to mitigate.\nThese techniques are often used to achieve the adversary's end goal.\n"}}, {"techniqueID": "AML.T0017", "score": 3, "showSubtechniques": true, "tactic": "resource-development"}, {"techniqueID": "AML.T0043.002", "score": 1, "tactic": {"id": "AML.TA0001", "name": "ML Attack Staging", "object-type": "tactic", "description": "An adversary is leveraging their knowledge of and access to the target system to tailor the attack.\n\nML Attack Staging consists of techniques adversaries use to prepare their attack on the target ML model.\nTechniques can include training proxy models, poisoning the target model, and crafting adversarial data to feed the target model.\nSome of these techniques can be performed in an offline manor and are thus difficult to mitigate.\nThese techniques are often used to achieve the adversary's end goal.\n"}}, {"techniqueID": "AML.T0042", "score": 2, "showSubtechniques": true, "tactic": {"id": "AML.TA0001", "name": "ML Attack Staging", "object-type": "tactic", "description": "An adversary is leveraging their knowledge of and access to the target system to tailor the attack.\n\nML Attack Staging consists of techniques adversaries use to prepare their attack on the target ML model.\nTechniques can include training proxy models, poisoning the target model, and crafting adversarial data to feed the target model.\nSome of these techniques can be performed in an offline manor and are thus difficult to mitigate.\nThese techniques are often used to achieve the adversary's end goal.\n"}}, {"techniqueID": "AML.T0015", "score": 4, "showSubtechniques": true, "tactic": "defense-evasion"}], "gradient": {"colors": ["#FFFFFF", "#F44336"], "minValue": 0, "maxValue": 15}}